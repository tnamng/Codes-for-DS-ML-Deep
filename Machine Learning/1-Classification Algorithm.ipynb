{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèles linéaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression logistique [défaut L2 régularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\"\"\" Params:\n",
    "    C = 1.0, qui est l'inverse de la force de régularization\n",
    "    (penalty='L2', solver='lbfg') (mặc định) || (penalty='l1', solver='liblinear')\n",
    "\"\"\"\n",
    "\n",
    "logreg.coef_, logreg.intercept_\n",
    "\n",
    "logred.fit(X_train, y_train)\n",
    "y_pred = logred.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_coef = logreg.coef_.reshape(-1,)\n",
    "logreg_intercept = logreg.intercept_\n",
    "plt.plot(range(len(X_train.columns)), logreg_coef)\n",
    "plt.xticks(range(len(X_train.columns)), X_train.columns, rotation=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = logreg.predict_proba(X_test)[:, 1]\n",
    "logreg.decision_function(X_test).shape\n",
    "# == (m,) or (m, n_class) for n_class >=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Linéaire: [défaut  L2 regu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "linsvc = LinearSVC()   \n",
    "\"\"\"Params:\n",
    "    C=1 l'inverse du force de régularization   \n",
    "\"\"\"\n",
    "linsvc.decision_function(X_test) #confidence scores for samples.\n",
    "#Khong co predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC()\n"
     ]
    }
   ],
   "source": [
    "- nhạy cảm với scalling yêu cầu standarNorme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Naive base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB   # all example points are binary  -->TEXT\n",
    "from sklearn.naive_bayes import MultinomialNB # all example points are dénombrement de qqch  -->TEXT\n",
    "from sklearn.naive_bayes import GaussianNB  # all example points are continuous\n",
    "\n",
    "\"\"\"\n",
    "    Params:\n",
    "    alpha : qui contrôle la complexité du modèle, et par conséquence la régularité du frontière de décision\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Considère les caractéristiques sont indépendants et traiter chaque caractérítique indépendement \n",
    "    --> rapide-->bon pour les données de grande dimention comme TEXT\n",
    "- La performance de génération est moins bonne que LogReg et LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les k plus proches voisins (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For finding best n_neighbors\n",
    "neighbors = np.arange(2,20)\n",
    "train_scores =[]\n",
    "test_scores =[]\n",
    "for i in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_scores.append(knn.score(X_train, y_train))\n",
    "    test_scores.append(knn.score(X_test, y_test))\n",
    "    \n",
    "plt.plot(train_scores, label=\"train score\")\n",
    "plt.plot(test_scores, label=\"test_score\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.ylabel(\"score\")\n",
    "plt.title(\"Score of train and test sets with hyperparameters\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM à noyau (Kernel SVM) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[machines à vecteurs de support = séparateur à vaste marge]**\n",
    "1. l'astuce deu noyau: transformer des caractéristiques d'orgine de manière non) linéaire pour obtenir des nouveaux caractéristique:  par estimer la distance des points de données  \n",
    "2. Puis appliquer un modèle linéaire sur les données avec des nouveau caractéristiques\n",
    "3. Prediction: \n",
    "        - Les échantillons qui se trouvent près de la frontière de décision entre les classes sont importants et s'appellent des vecteur supports\n",
    "        - mesurer la distance de nouveau example avec des vecteur supports\n",
    "        - Une décision est éffectué à partir de ces distances et l'importance de ces vecteurs supports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "\"\"\"params:\n",
    "    C=1.0 # tham số ngược của  régularization\n",
    "    (kernel='rbf', gamma='scale')\n",
    "        # l'inverse du largeur du noyau gaussien = tầm ảnh hưởng của mỗi échangtillon. \n",
    "        gamma bé, tầm ảnh hưởng lớn, các examples giống nhau, frontière de décision trơn. Cần phải xem nhiều điểm để\n",
    "        construct the hyperplane.\n",
    "        Gamma (gamma, default gamma='auto' which uses 1/n_features): \n",
    "    (kernel = 'poly', d, coef0 r) : more in  NLP.  d=2 (quadratic) is common\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** \n",
    "- Tốt cho Dữ liệu rất ít chiều or rất chiều chiều\n",
    "- Puissant pour les jeux de données de taille moyenne avec des caractéristiques dont le sens est similaire\n",
    "\n",
    "Yếu: SVM très senstive au scale. Les données nên có giá trị 0, 1. Ta dùng MinMaxScaler\n",
    "Dữ liệu lớn không hiệu quả."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- larger gamma leads to more complex boundaries\n",
    "- smaller gamma leads to smoother boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression: Is a linear classifier\n",
    "Can use with kernels, but slow \n",
    "Outputs meaningful probabilities\n",
    "Can be extended to multiclass\n",
    "All data points a(ect ,t L2 or L1 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(SVM):\n",
    "Is a linear classifier\n",
    "Can use with kernels, and fast\n",
    "Does not naturally output probabilities\n",
    "Can be extended to multiclass Only \"support vectors\" a(ect ,t Conventionally just L2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree and the others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=123)\n",
    "\"\"\"Params:\n",
    "    criterion='gini'/'entropy'\n",
    "    max_depth=None, max_features=None, max_leaf_nodes=None,  : Complexité du TREE\n",
    "    random_state=xxx\n",
    "\"\"\"\n",
    "HAVE: predict_proba va decision_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "dot_data = tree.export_graphviz(clf, out_file=None,\n",
    "                                rounded=True,\n",
    "                                filled=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "Image(graph.create_png())\n",
    "\n",
    "graph.write_pdf(\"tree.pdf\")   # to pdf\n",
    "graph.write_png(\"tree_png.png\")    # to png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark**\n",
    "- Không cần scale, Dễ interpreter (xem cây được), có hàm feature_important \n",
    "- Dễ overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Random Forest [using soft voting->probability/decision]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_clf = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "\"\"\"Params:\n",
    "    n_estimators=Số lượng cây\n",
    "    random_state=None,\n",
    "\n",
    "    criterion='gini', \n",
    "    max_depth=None, max_leaf_nodes=None \n",
    "    max_features='auto', \n",
    "    \n",
    "\"\"\"\n",
    "predict_proba(X) Not Decision_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- Không cần scalling, có tính chất feature_important, tránh được overfitting\n",
    "- Nhiều features thì không hiệu quả (vd TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Gradient Bossting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators=123, learning_rate = 0.002, random_state=xxx)\n",
    "\n",
    "\"\"\"Params:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Có loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SKLEARN API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "clf = xgb.XGBClassifier(objective='binary:logistic'/\"multi:softmax\" ||#'reg:linear' for xgb.XGBRegressor\n",
    "                        booster = \"gbtree\" (mặc đinh)/\"gblinear\"/\"dart\"\n",
    "                        learning_rate=0.1, n_estimators=10, seed=123)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "model.score(X_test,y_test)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBOOST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data=X_train,label=y_train)\n",
    "dtest = xgb.DMatrix(data=X_test,label=y_test)\n",
    "params = {\"booster\":\"gbtree\",\"objective\":\"reg:linear\"}\n",
    "\n",
    "clf.train/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation score: Xgb.cv with DMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\"objective\":\"binary:logistic\"/'reg:linear',\"max_depth\":4}\n",
    "params[\"lambda\"] -->L2 regu\n",
    "params[\"alpha\"] --->L1 regu\n",
    "params = {\"objective\":\"reg:linear\",'colsample_bytree': 0.3,'learning_rate': 0.1, 'max_depth': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier( .....'parmas'....)\n",
    "params = clf.get_xgb_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data=X,label=y)  #Data Structure for XGBOOST, phai dung cai nay trong CV\n",
    "cv_results = xgb.cv(dtrain=dtrain, params=params, \n",
    "                    nfold=4, num_boost_round=10, metrics=\"error\"/'auc'>>'mae'/'rmse', as_pandas=True)\n",
    "#num_boost_round = so luong TREE su dung\n",
    "print(\"Accuracy: %f\" %((1-cv_results[\"test-error-mean\"]).iloc[-1]))\n",
    "print((cv_results[\"test-auc-mean\"]).iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch/RandomSearch (n_iter=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "gbm = xgb.XGBRegressor()\n",
    "param_grid = {'learning_rate': [0.01,0.1,0.5,0.9], 'n_estimators': [200],'subsample': [0.3, 0.5, 0.9]}\n",
    "\n",
    "\n",
    "grid_mse = GridSearchCV(estimator = gbm,param_grid, param_grid, scoring='neg_mean_squared_error', cv=4, verbose=1)\n",
    "grid_mse.fit(dtrain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
