{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Linéaire model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.coef_   # mang\n",
    "linreg.intercept_ # number\n",
    "\n",
    "linreg.score(X_test, y_test)  #= R^2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Regularization (L1:Lassio, L2:Ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark** Enough data, Regu becomms less important (<400 point = it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "\n",
    "#Regularization lam cho Slop nho di\n",
    "ridge = Ridge()\n",
    "\"\"\"params:\n",
    "    alpha = 1.0 : Force de la régularization\n",
    "\"\"\"\n",
    "#Nhin chung la good vi ta giu lai tat cac cac tham so\n",
    "lasso = Lasso(alpha=0.4, normalize=True)\n",
    "\"\"\"params:\n",
    "    alpha = 1.0 : Force de la régularization\n",
    "\"\"\"\n",
    "#if you have a large amount of features and expect only a few of them to be\n",
    "#important, Lasso might be a better choice than Ridge\n",
    "ElasticNet(alpha=0.1, l1_ration=0.5)\n",
    "\"\"\"params:\n",
    "    alpha = 1.0  Force de la L1-régularization\n",
    "    l1_ration in [0, 1]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_space = np.logspace(-4, 0, 50)\n",
    "ridge_scores = []\n",
    "ridge_scores_std = []\n",
    "\n",
    "# Create a ridge regressor: ridge\n",
    "\n",
    "ridge.alpha = alpha\n",
    "plt.scatter(X_train_1D, y_train.values.reshape(-1,1))\n",
    "\n",
    "h=0.02 \n",
    "x = np.arange(X_train_1D.min(), X_train_1D.max()+h, h)\n",
    "plt.plot(x, reg.coef_ * x + reg.intercept_)\n",
    "\n",
    "\n",
    "\n",
    "plt.bar(range(len(X.columns)), reg.coef_)\n",
    "plt.xticks(range(len(X.columns)), X.columns, rotation=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. PolyRegression(Linéaire regression avec nonlinear caractéristique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_feature = PolynomialFeatures(degree =xxx)\n",
    "X__train_poly = poly_feature.fit_transform(X_train)\n",
    "\n",
    "linreg.fit(X_train_poly, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. SVM Linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Params:\\n    C=1 l'inverse du force de régularization   \\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "linsvr = LinearSVR() \n",
    "\"\"\"Params:\n",
    "    C=1 l'inverse du force de régularization   \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors = ...)\n",
    "\n",
    "neighbors = np.arange(2,20)\n",
    "train_scores =[]\n",
    "test_scores =[]\n",
    "for i in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_scores.append(knn.score(X_train, y_train))\n",
    "    test_scores.append(knn.score(X_test, y_test))\n",
    "    \n",
    "plt.plot(train_scores, label=\"train score\")\n",
    "plt.plot(test_scores, label=\"test_score\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.ylabel(\"score\")\n",
    "plt.title(\"Score of train and test sets with hyperparameters\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SVM à noyau (Kernel SVM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svc = SVR()\n",
    "\"\"\"params:\n",
    "    C=1.0 # tham số ngược của  régularization\n",
    "    (kernel='rbf', gamma='scale')\n",
    "        # l'inverse du largeur du noyau gaussien = tầm ảnh hưởng của mỗi échangtillon. \n",
    "        gamma bé, tầm ảnh hưởng lớn, các examples giống nhau, frontière de décision trơn. Cần phải xem nhiều điểm để\n",
    "        construct the hyperplane.\n",
    "        Gamma (gamma, default gamma='auto' which uses 1/n_features): \n",
    "    (kernel = 'poly', d, coef0 r) : more in  NLP.  d=2 (quadratic) is common\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Tree va nhung thu khac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a.Basic Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "treereg = DecisionTreeRegressor()\n",
    "\"\"\"Params:\n",
    "    criterion='gini'/'entropy'\n",
    "    max_depth=None, max_features=None, max_leaf_nodes=None,  : Complexité du TREE\n",
    "    random_state=xxx\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "dot_data = tree.export_graphviz(clf, out_file=None,\n",
    "                                rounded=True,\n",
    "                                filled=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "Image(graph.create_png())\n",
    "\n",
    "graph.write_pdf(\"tree.pdf\")   # to pdf\n",
    "graph.write_png(\"thi.png\")    # to png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=100, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Bossting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegeressor\n",
    "\n",
    "gb = GradientBoostingRegressor(n_estimators=xxx, learning_rate = xxx,random_state=xxx)\n",
    "\n",
    "\"\"\"Params:\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
