{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Pandas overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sơ bộ: info chung (shape, type), CHECK unique, duplicate, NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.tail()\n",
    "df.sample()\n",
    "\n",
    "df.info() # show dtype of dataframe\n",
    "df.shape\n",
    "df.dtypes// df.dtypes.count()\n",
    "\n",
    "df.describe() # numerical features, \n",
    "train_df.describe(include=['O']/'category')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.var(series)\n",
    "np.mean(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check NaN and Duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tran NaN, Duplicate: kết quả là TRUE/FALSE\n",
    "df.isnull().sum()  #--->df['col'].isnull()\n",
    "df.isnull().sum().sum()\n",
    "\n",
    "# Duplicate: không thiên về numerics\n",
    "duplicates = df.duplicated()# all columns\n",
    "duplicates = df.duplicated('col1'/['col1', 'col2'], keep = False)  #lấy index\n",
    "df[duplicates]\n",
    "\n",
    "df/df['col'].duplicated().any()\n",
    "df/df['col'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simple modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. For  NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()   # Drop any rows which have any nan\n",
    "df.dropna(subset=['VersionControl']) # Drop rows with missing values in a specific column\n",
    "df.dropna(how='all') # Nếu toàn bộ dòng là NaN thì ta xoá dòng đấy\n",
    "\n",
    "df.dropna(axis=1, inplace = True)  # Drop columns that have any nans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. For duplicate values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=\"col1\"/['col1', 'col2'], inplace = True) \n",
    "#xem trong col1 co duplicate khong, neu co thi bo di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xu ly: lay gia tri trung binh\n",
    "df3 = df.groupby([\"col1\"]).agg('col3':'mean', 'col4':'max').reset_index()\n",
    "???? df4 = df.groupby([\"col1\", \"col2\"])[\"col3\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Simple modification on: Index and colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index()\n",
    "df.reset_index(drop=True)\n",
    "df_new = df.set_index(\"col2\"/['col2', 'col3'])\n",
    "\n",
    "df.sort_index()\n",
    "df.sort_index(level=[\"col2\", \"col3\"], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "df.rename(columns = {'old_col1':'new_col1'}, inplace = True) #giống mapping\n",
    "df.drop('col1'/['col1, col2'], axis = 1, inplace = True) # bỏ colums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Overview on one colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thiên về numerics\n",
    "df.sort_values(\"col1\", ascending=False)\n",
    "df.sort_values(['col1', 'col2'], ascending = [True, False]) \n",
    "\n",
    "#Thiên về category\n",
    "df['col'].unique()\n",
    "df['col'].value_counts()\n",
    "df['col'].value_counts(ascending=True)\n",
    "df['col1'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II.  Categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overview category and simple transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[col1].value_counts()   # to check the values of the column 1\n",
    "df[col1].value_counts().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col1'] = df[\"col1\"].astype('category')\n",
    "\n",
    "#WITH ORDER\n",
    "from pandas.api.types import CategoricalDtype\n",
    "cat_type = CategoricalDtype(categories=[\"b\", \"c\", \"d\"], ordered=True)\n",
    "df.col1 = df.col1.astype(cat_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Label encoding (Chuyển thành số 1, 2, 3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  a. Label encoding with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_map = {'column..': {'categories': desired_values}} # Dictionary of dictionayr\n",
    "df_replace = df.replace(replace_map)   // df.replace(replace_map, inplace=True) \n",
    "\n",
    "titanic_numeric['EmbNum'].replace(['S','C','Q'],[0,1,2]).astype(float)\n",
    "\n",
    "df[\"sub_enc\"] = df[\"subscribed\"].apply(lambda val:1 if val == \"y\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 and the other (chỉ có 2 số mà thôi)\n",
    "df['column_1'] = np.where(df['column_1'].str.contains('US'), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['column1'] =  df['column1'].cat.codes  # Mã hóa category thành SỐ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Label encoding with Sci-Kit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder  # DUNG CHO SERIES\n",
    "lb_make = LabelEncoder()\n",
    "df['carrier_code'] = lb_make.fit_transform(df['carrier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder #with order\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
    "\n",
    "ordinal_encoder.categories_ # Dau ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoder = OneHotEncoder(sparse=False)\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "housing_cat_1hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. One-hot encoding with Pandas/Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy = pd.get_dummies(df)   # Tác động đến ALL columns dạng object\n",
    "pd.concat(df, df_dummy)\n",
    "\n",
    "df_new = pd.get_dummnies(data = df, columns = ['col1', 'col2'], drop_first = True)  \n",
    "# Tiền tố cho column mới prefix = [xxx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder   \n",
    "# # CO THE DUNG DUOC CHO DATAFRAME\n",
    "## Takes the column of integers\n",
    "\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "one_hot_encoder.fit(df)\n",
    "\n",
    "colors_df_encoded = one_hot_encoder.transform(colors_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Numerical values to category: qcut/map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. qcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['0-200K', '200K-500K', '500K+']\n",
    "df['income_group'] = pd.qcut(df['household_income'], q = 3, labels = group_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = [0,200000,500000,np.inf]\n",
    "df['income_group'] = pd.cut(df['household_income'], bins=ranges, labels=group_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. map(function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_exp(years):\n",
    "    if years > 7:\n",
    "        return 'Expert'\n",
    "    elif years > 5:\n",
    "        return 'Confirmé'\n",
    "    elif years > 3:\n",
    "        return 'Avancé'       \n",
    "    else:\n",
    "        return 'Débutant'\n",
    "    \n",
    "df['Experience']=df['Experience'].map(label_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chú ý Histogram, oulier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_Salary'] = pd.to_numeric(df['Raw_Salary'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. String"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. String columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col1'] = df['col1'].str.replace('xx', 'xxxxx') \n",
    "    //..str.upper()%%!//.str.lower()\n",
    "    //.str.strip()\n",
    "    //.str.contains(\"+|-\")\n",
    "    //str.split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['inventory'] = df['search_type'].str.contains('Inventory', na=False)\n",
    "# na=False returns False when it is a missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_columns = df.stop_date.str.cat(df.stop_time, sep =\" \")\n",
    "df['stop_datetime'] = pd.to_datetime(combined_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reguler expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = re.compile('\\$\\d*\\.\\d{2}')\n",
    "result = pattern.match('$17.89')  ---> match kiểm tra từ chỗ đầu tiên không giống như re.search\n",
    "bool(result)\n",
    "\n",
    "# Write a pattern to match sentence endings: sentence_endings\n",
    "sentence_endings = r\"[.?!]\"\n",
    "\n",
    "# Split my_string on sentence endings and print the result\n",
    "print(re.split(sentence_endings, my_string))\n",
    "\n",
    "# Find all capitalized words in my_string and print the result\n",
    "capitalized_words = r\"[A-Z]\\w+\"\n",
    "print(re.findall(capitalized_words, my_string))\n",
    "\n",
    "# Split my_string on spaces and print the result\n",
    "spaces = r\"\\s+\"\n",
    "print(re.split(spaces, my_string))\n",
    "\n",
    "# Find all digits in my_string and print the result\n",
    "digits = r\"\\d+\"\n",
    "print(re.findall(digits, my_string))\n",
    "\n",
    "\n",
    "\n",
    "OR =  |\n",
    "group = ()\n",
    "explicit character = []\n",
    "\n",
    "\n",
    "match_digits_and_words = ('(\\d+|\\w+)')\n",
    "re.findall(match_digits_and_words, 'He has 11 cats.')\n",
    "\n",
    "KQ: ['He', 'has', '11', 'cats']\n",
    "re.match('abc', 'abcdef')\n",
    "\n",
    "\n",
    "if bool(pattern.match(icost)) and bool(pattern.match(tef)):\n",
    "icost = icost.replace(\"$\", \"\")\n",
    "tef = tef.replace(\"$\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Date-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new_date'] = pd.to_datetime(df['string_date'])\n",
    "df['Start date'] = pd.to_datetime(rides['string_date'], format = \"%Y-%m-%d %H:@%M:%S\", errors = 'coerce')\n",
    "# Return NA for rows where conversion failed\n",
    "\n",
    "birthdays['Birthday'] = pd.to_datetime(birthdays['Birthday'],infer_datetime_format=True,errors = 'coerce')\n",
    "# Attempt to infer format of each date\n",
    "users['Birthday'].dt.year/month/day\n",
    "\n",
    "today_date = dt.date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ĐỔI NGÀY THÀNH STRING\n",
    "birthdays['Birthday'] = birthdays['Birthday'].dt.strftime(\"%d-%m-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELTA TIME\n",
    "rides['Duration'] = rides['End date'] - rides['Start date']\n",
    "rides['Duration'].dt.total_seconds().head(5)\n",
    "\n",
    "rides['Duration'].sum() / timedelta(days=91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average duration by month: GROYPBY TIME SERIES\n",
    "rides.resample('M', on = 'Start date')['Duration seconds'].mean()\n",
    "Hoặc dùng groupby index.month cũng được cũng được"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides['Start date'].head(3).dt.tz_localize('America/New_York')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Turn strings into dates with .strptime() and dates into strings with .strftime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "To turn date objects into strings, use the .isoformat() or .strftime() methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Missing values (more): \n",
    "    - np.nan, None, \"NA\", 'na', \"\" \n",
    "    - and other ones without meaning: eg. Age<0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "string_data = pd.Series(['aardvark', 'artichoke', np.nan/None, 'avocado'])\n",
    "# isnull nhật biết được np.nan và None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of missing value\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "# Visualize missingness\n",
    "msno.matrix(airquality)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_vals = [\"NA\", \"\", None, np.NaN]\n",
    "missing = df.isin(missing_vals)\n",
    "missing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Remove "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()   # Drop any rows which have any nan\n",
    "df.dropna(subset=['VersionControl']) # Drop rows with missing values in a specific column\n",
    "df.dropna(how='all') # Nếu toàn bộ dòng là NaN thì ta xoá dòng đấy\n",
    "\n",
    "df.dropna(axis=1, inplace = True)  # Drop columns that have any nans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Repalce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col'] = df['col'].fillna(number/string)\n",
    "df['col'].fillna(number/string, inplace = True)\n",
    "df = df.fillna(value = {'col1':'desired_values' ,'col2':0}) # dict = col:new_value                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = Imputer(missing_values = nan, strategy = 'mean'/'median', axis = 0)  # Numercis  \n",
    "imputer = Imputer(missing_values = 'NaN', strategy = \"most_frequent\", axis = 0)  # Object(category) and numerics\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = \"constant\", axis = 0)  # Object and numerics, \n",
    "\n",
    "\n",
    "imputer = imputer.fit(X[:, 1:3])  # tap trung vao columns Numeris HOAC String\n",
    "X[:, 1:3] = imputer.transform(X[:, 1:3])\n",
    "\n",
    "imputer.statistics_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
